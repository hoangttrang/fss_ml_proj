{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3450f312-8695-4638-b71f-530a294f05fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Aggregating Location Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f498113-c60d-445b-9b77-ba3371c12fdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+h3_hint": "",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.pandas import read_excel\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import gc\n",
    "import os \n",
    "import re\n",
    "import datetime\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import rowcol\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cdc60191-acc1-459e-bfe6-55156588ef09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7906fe33-b090-4058-98a2-1b0677085e46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Accident Data Preprocessing\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "353e0a85-70f7-4c1d-b89c-1283cb12dac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fusionsite_regional_df_pandas =  pd.read_excel(\"/dbfs/FileStore/tables/FusionSite_Services_Regional_Footprint_January_2025.xlsx\")\n",
    "accident_df_pandas = pd.read_csv(\"/dbfs/FileStore/tables/accident_register_combined_driverid.csv\")\n",
    "monthly_claims_insurance_pandas = pd.read_csv(\"/dbfs/FileStore/tables/monthly_claims_insurance_driverid.csv\")\n",
    "us_city_states_pandas = pd.read_csv(\"/dbfs/FileStore/tables/uscities.csv\")\n",
    "full_driver_details = pd.read_csv(\"/dbfs/FileStore/tables/full_driver_details.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dc9afab-c839-472f-86c1-fc72f21e9158",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acdc430c-af63-468e-a210-729af146806b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Parsing Accident Location into city, state, zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9c6f44f-2913-4774-a9e9-5465a4780e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make a dictionary that maps stat acronyms to full names\n",
    "acronym_full_name = us_city_states_pandas[[\"state_id\", \"state_name\"]].drop_duplicates()\n",
    "\n",
    "state_abbrevs = us_city_states_pandas[\"state_id\"].unique()\n",
    "full_state_names = us_city_states_pandas[\"state_name\"].unique()\n",
    "state_names  = dict(zip(acronym_full_name[\"state_id\"], acronym_full_name[\"state_name\"]))\n",
    "\n",
    "# Lowercase all strings in state_abbrevs and \n",
    "# Lower case key and value in state_names dict\n",
    "state_abbrevs = [abbrev.lower() for abbrev in state_abbrevs]\n",
    "state_names = {key.lower(): value.lower() for key, value in state_names.items()}\n",
    "\n",
    "accident_df_pandas[\"Location of Accident (street, city, state)\"] = accident_df_pandas[\"Location of Accident (street, city, state)\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e44438-be6d-444c-9d8f-63a89c78c21c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "street_types = ['st',\n",
    " 'ave',\n",
    " 'blvd',\n",
    " 'rd',\n",
    " 'dr',\n",
    " 'ln',\n",
    " 'ct',\n",
    " 'pkwy',\n",
    " 'cir',\n",
    " 'way',\n",
    " 'street',\n",
    " 'avenue',\n",
    " 'boulevard',\n",
    " 'road',\n",
    " 'drive',\n",
    " 'lane',\n",
    " 'court',\n",
    " 'parkway',\n",
    " 'circle',\n",
    " 'highway',\n",
    " 'hwy',\n",
    " 'route',\n",
    " 'rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12c3ef2b-ed87-4feb-8688-ac0dc8b5d391",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "non_city_terms = ['block of',\n",
    " 'junction of',\n",
    " 'intersection',\n",
    " 'corner of',\n",
    " 'box',\n",
    " 'rural route',\n",
    " 'rr',\n",
    " 'mile marker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1c0cbce-af4c-4c12-8636-d83e5fdf3dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_location(location):\n",
    "    if not isinstance(location, str) or not location.strip():\n",
    "        return None, None, None\n",
    "    \n",
    "    # Clean and standardize the location string\n",
    "    location = location.strip()\n",
    "    \n",
    "    # Extract ZIP code using regex - find all matches and take the last one\n",
    "    zip_pattern = r'\\b(\\d{5}(?:-\\d{4})?)\\b'\n",
    "    zip_matches = re.findall(zip_pattern, location)\n",
    "    zip_code = zip_matches[-1] if zip_matches else None\n",
    "    \n",
    "    # Extract state\n",
    "    state = None\n",
    "    state_index = -1\n",
    "    \n",
    "    # First check for state abbreviations\n",
    "    for abbrev in state_abbrevs:\n",
    "        pattern = r'\\b' + abbrev + r'\\b'\n",
    "        match = re.search(pattern, location)\n",
    "        if match:\n",
    "            state = abbrev\n",
    "            state_index = match.start()\n",
    "            break\n",
    "    \n",
    "    # If no abbreviation found, check for full state names\n",
    "    if state is None:\n",
    "        for state_name, abbrev in state_names.items():\n",
    "            if state_name in location:\n",
    "                state = abbrev\n",
    "                state_index = location.find(state_name)\n",
    "                break\n",
    "    \n",
    "    return state, zip_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16d70d75-0af8-4bff-a33c-3ee677fe96ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create new columns for the extracted information\n",
    "accident_df_pandas['state'] = None\n",
    "accident_df_pandas['zip'] = None\n",
    "\n",
    "# Process each row\n",
    "for idx, row in accident_df_pandas.iterrows():\n",
    "    location = row[\"Location of Accident (street, city, state)\"]\n",
    "    \n",
    "    if location:\n",
    "        state, zip_code, *other_values = parse_location(location)\n",
    "        accident_df_pandas.at[idx, 'state'] = state\n",
    "        accident_df_pandas.at[idx, 'zip'] = zip_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96adcd81-7852-4763-8ae0-813aee9a7a4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "known_cities = list(fusionsite_regional_df_pandas[fusionsite_regional_df_pandas[\"City\"].notnull()][\"City\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50d7860-4bb3-44de-bf6a-0e2154e6043c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "known_cities.append(\"austin\")\n",
    "known_cities.append(\"black mountain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76e39811-9134-4b38-a703-3aae99dfbed7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use word boundaries to ensure we match complete words, not substrings\n",
    "pattern = '|'.join([fr\"\\b{re.escape(street_type)}\\b[\\s\\.,]\" for street_type in street_types])\n",
    "city_names_with_street_name = list(us_city_states_pandas[us_city_states_pandas[\"city\"].str.contains(pattern, na=False, case=False)][\"city\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b36684fa-4f42-4201-9290-0ca05090e81c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "known_cities = known_cities + city_names_with_street_name\n",
    "known_cities = [city for city in known_cities if all(term not in city.lower() for term in [\"college\", \"court house\", \"mobile home park\", \"addition\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c426dec-411d-4322-a556-43bda1928eab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "unique_city_names = us_city_states_pandas.groupby(\"city\").size()[us_city_states_pandas.groupby(\"city\").size() == 1]\n",
    "# lowercase unique_city_names\n",
    "unique_city_names = [name.lower() for name in list(unique_city_names.index)]\n",
    "\n",
    "city_names = [name.lower() for name in us_city_states_pandas[us_city_states_pandas[\"city\"].notnull()][\"city\"].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88fff465-0a99-4fb8-b688-e948c08f8263",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_city(location):\n",
    "    if not isinstance(location, str) or not location.strip():\n",
    "        return None\n",
    "    \n",
    "    # Clean the location string\n",
    "    location = location.strip().lower()\n",
    "    \n",
    "    # Special case handling for problematic patterns\n",
    "    if \"lavaca st\" in location and \"austin\" in location:\n",
    "        return \"Austin\"\n",
    "    \n",
    "    # Handle \"place in [city]\" pattern\n",
    "    place_in_match = re.search(r'(place|pl)\\s+in\\s+([a-z]+)', location, re.IGNORECASE)\n",
    "    if place_in_match:\n",
    "        potential_city = place_in_match.group(2)\n",
    "        # Check if this isn't a state and is followed by a state\n",
    "        if potential_city not in state_abbrevs:\n",
    "            # Check if a state follows\n",
    "            after_city = location[place_in_match.end():]\n",
    "            if any(state in after_city for state in state_abbrevs):\n",
    "                return potential_city.title()\n",
    "    \n",
    "    # If it's just a state abbreviation, return None\n",
    "    if location in state_abbrevs:\n",
    "        return None\n",
    "    \n",
    "    # Check for known city-state pairs\n",
    "    for city in known_cities:\n",
    "        if city.lower() in location:\n",
    "            return city.title()\n",
    "    \n",
    "    # Split by commas\n",
    "    parts = [p.strip() for p in location.split(',')]\n",
    "    \n",
    "    # Case 1: Find city before state in comma format (city, state)\n",
    "    if len(parts) >= 2:\n",
    "        for i in range(len(parts) - 1):\n",
    "            current_part = parts[i]\n",
    "            next_part = parts[i + 1]\n",
    "            \n",
    "            # Check if next part contains a state code\n",
    "            has_state = False\n",
    "            for state in state_abbrevs:\n",
    "                if state in next_part.split():\n",
    "                    has_state = True\n",
    "                    break\n",
    "            \n",
    "            # Check if current part has street type (with or without period)\n",
    "            words = current_part.split()\n",
    "            has_street_type = False\n",
    "            for word in words:\n",
    "                word_no_period = word.replace('.', '')\n",
    "                if word_no_period in street_types:\n",
    "                    has_street_type = True\n",
    "                    break\n",
    "            \n",
    "            if has_state and not has_street_type:\n",
    "                # Remove any leading street numbers\n",
    "                city = re.sub(r'^\\d+\\s+', '', current_part)\n",
    "                return city.title()\n",
    "    \n",
    "    # Pattern for street-type + city + state format (no commas)\n",
    "    for street_type in street_types:\n",
    "        # Try with and without period\n",
    "        for st in [street_type, street_type + '.']:\n",
    "            # Pattern like \"lavaca st. austin texas\" or \"6th st. brownsville tx\"\n",
    "            pattern = r'(?:\\d+\\s+)?(?:\\w+\\s+)?' + re.escape(st) + r'\\s+([a-z]+)\\s+(?:' + '|'.join(state_abbrevs + full_state_names) + r')\\b'\n",
    "            match = re.search(pattern, location, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).title()\n",
    "    \n",
    "    # Pattern for road names + city + state (e.g., \"3709 cove mountain rd sevierville, tn\")\n",
    "    for street_type in street_types:\n",
    "        pattern = r'\\b' + re.escape(street_type) + r'\\s+([a-z]+)(?:\\s*,\\s*|\\s+)(?:' + '|'.join(state_abbrevs) + r')\\b'\n",
    "        match = re.search(pattern, location, re.IGNORECASE)\n",
    "        if match:\n",
    "            potential_city = match.group(1)\n",
    "            if potential_city not in street_types and not any(c.isdigit() for c in potential_city):\n",
    "                return potential_city.title()\n",
    "    \n",
    "    # Case for any city immediately before state\n",
    "    for state in state_abbrevs:\n",
    "        pattern = r'([a-z]+)\\s*,?\\s*\\b' + state + r'\\b'\n",
    "        match = re.search(pattern, location)\n",
    "        if match:\n",
    "            potential_city = match.group(1)\n",
    "            # Verify this isn't a street type\n",
    "            if potential_city not in street_types and not potential_city.isdigit():\n",
    "                return potential_city.title()\n",
    "    \n",
    "    # Fallback to original behavior for other cases\n",
    "    return None\n",
    "\n",
    "def extract_cities_from_df(df, location_column):\n",
    "    return df[location_column].apply(extract_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1264f0e4-fa4a-4714-a542-5ef6d9e0e65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing individual examples:\n\nLocation: '3709 cove mountain rd sevierville, tn'\nExtracted city: Sevierville\n\nLocation: 'norriswood ave, memphis ,tn'\nExtracted city: Memphis\n\nLocation: '411 woodycrest nashville tn'\nExtracted city: Nashville\n\nLocation: '6631 old settler roads, waxhaw, nc 28173'\nExtracted city: Waxhaw\n\nLocation: '28 wendy lane asheville, nc 28805'\nExtracted city: Asheville\n\nLocation: 'lavaca st. austin texas'\nExtracted city: Austin\n\nLocation: 'SC'\nExtracted city: None\n\nLocation: '198 e grover street, shelby, nc'\nExtracted city: Shelby\n\nLocation: 'prospect place in carrboro, nc'\nExtracted city: Carrboro\n\nLocation: 'Hwy 9 Black Mountain NC'\nExtracted city: Black Mountain\n\nLocation: '6th st. brownsville tx'\nExtracted city: Brownsville\n\nLocation: '9630 university city blvd, charlotte, nc'\nExtracted city: Charlotte\n"
     ]
    }
   ],
   "source": [
    "# Test examples\n",
    "test_locations = [\n",
    "    \"3709 cove mountain rd sevierville, tn\" ,\n",
    "    \"norriswood ave, memphis ,tn\",\n",
    "    \"411 woodycrest nashville tn\",\n",
    "    \"6631 old settler roads, waxhaw, nc 28173\",\n",
    "    \"28 wendy lane asheville, nc 28805\",\n",
    "    \"lavaca st. austin texas\",\n",
    "    \"SC\",\n",
    "    \"198 e grover street, shelby, nc\",\n",
    "    \"prospect place in carrboro, nc\",\n",
    "    \"Hwy 9 Black Mountain NC\",\n",
    "    \"6th st. brownsville tx\", \n",
    "    \"9630 university city blvd, charlotte, nc\"\n",
    "]\n",
    "\n",
    "# Test each example individually\n",
    "print(\"Testing individual examples:\")\n",
    "for loc in test_locations:\n",
    "    result = extract_city(loc)\n",
    "    print(f\"\\nLocation: '{loc}'\")\n",
    "    print(f\"Extracted city: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af57b1a9-408d-412f-8097-c7ad6a91f031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas['city'] = extract_cities_from_df(accident_df_pandas, 'Location of Accident (street, city, state)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac365d1-1bf4-4754-8416-005ab1278a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_city_name(city):\n",
    "    if city is None:\n",
    "        return city\n",
    "    return re.sub(r'^\\D*\\d+\\s*', '', city)\n",
    "\n",
    "accident_df_pandas['city'] = accident_df_pandas['city'].apply(clean_city_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a767528-c93f-44d9-9ce4-ecba9ec9d2f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using DBA to map accident to its corresponding site location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73150287-0a2f-456a-93e7-3d5f352cf1d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "multiple_location_dbas = list(fusionsite_regional_df_pandas.groupby(\"Brand\").size()[fusionsite_regional_df_pandas.groupby(\"Brand\").size() > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb228e56-eae2-45b9-81b4-79143d95f5ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas = accident_df_pandas[~accident_df_pandas[\"DBA\"].str.contains(\"Home Office\", na = False)]\n",
    "fusionsite_regional_df_pandas.dropna(subset=[\"Zip\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12080dd5-dca7-46a1-86b1-3957d1f3fa8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas[\"DBA\"] = accident_df_pandas[\"DBA\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65ba80e4-c135-4ece-91e8-6901a1c0d4a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get unique DBA values that are not in the 'Brand' column\n",
    "dba_values = accident_df_pandas[~accident_df_pandas[\"DBA\"].isin(fusionsite_regional_df_pandas[\"Brand\"])][\"DBA\"].unique()\n",
    "\n",
    "# Create a list of possible 'Brand' values from fusionsite_regional_df_location_info\n",
    "brand_values = fusionsite_regional_df_pandas[\"Brand\"].tolist()\n",
    "\n",
    "# Map DBA values to the closest Brand using fuzzy matching\n",
    "mapped_dba_to_brand = {}\n",
    "for dba in dba_values:\n",
    "    closest_match, score = process.extractOne(dba, brand_values)\n",
    "    mapped_dba_to_brand[dba] = closest_match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a6ed3c-1d61-46fb-a01e-299e67a94a77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location of Accident (street, city, state)</th>\n",
       "      <th>DBA</th>\n",
       "      <th>General Manager</th>\n",
       "      <th>Date of Accident</th>\n",
       "      <th>Date Reported</th>\n",
       "      <th>Fatality</th>\n",
       "      <th>insured_driver_name</th>\n",
       "      <th>Copy of Sate or Insurance Report</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Summary of Accident</th>\n",
       "      <th>Claim Number</th>\n",
       "      <th>Total Incurred</th>\n",
       "      <th>Year</th>\n",
       "      <th>Region</th>\n",
       "      <th>Time of Accident</th>\n",
       "      <th>APMM Recordable</th>\n",
       "      <th>Notes</th>\n",
       "      <th>insured_first_name</th>\n",
       "      <th>insured_last_name</th>\n",
       "      <th>driver_first_name</th>\n",
       "      <th>driver_last_name</th>\n",
       "      <th>driver_id</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>tn</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shaun Huffman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09 PC 000000289012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shaun</td>\n",
       "      <td>Huffman</td>\n",
       "      <td>Shaun</td>\n",
       "      <td>Huffman</td>\n",
       "      <td>4041709.0</td>\n",
       "      <td>tn</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Location of Accident (street, city, state)        DBA  ...   zip  city\n",
       "52                                         tn  Nashville  ...  None  None\n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accident_df_pandas[accident_df_pandas[\"DBA\"] == 'Nashville']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d7931ac-29fa-44b0-8d26-4eb4ef24de46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "del mapped_dba_to_brand['West Florida']\n",
    "del mapped_dba_to_brand['Nashville']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b9ee527-7083-433d-a6c1-4781a30fd4fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cities_in_dba_names = [\"Fayetteville\", \"Augusta\", \"Columbia\", \"Little Rock\"]\n",
    "\n",
    "def assign_city(dba):\n",
    "    if \"Woodycrest\" in dba:\n",
    "        return \"Nashville\"\n",
    "    for city in cities_in_dba_names:\n",
    "        if city in dba:\n",
    "            return city\n",
    "    return None\n",
    "\n",
    "# Only assign city if current city is null\n",
    "\n",
    "accident_df_pandas['city'] = accident_df_pandas.apply(\n",
    "    lambda row: assign_city(row['DBA']) if pd.isnull(row['city']) else row['city'], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b370bda8-e52b-45de-acad-138ad8f0a6f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fix fuzzy wuzzy mappings after manual review\n",
    "mapped_dba_to_brand['Arkansas Portables'] = 'Arkansas Portable Toilets'\n",
    "mapped_dba_to_brand['ACP'] = 'A Clean Portoco'\n",
    "mapped_dba_to_brand['ASC'] =  'A Sani-Can'\n",
    "mapped_dba_to_brand['Fayetteville'] = 'Arkansas Portable Toilets'\n",
    "mapped_dba_to_brand['AR Fayeteville'] = 'Arkansas Portable Toilets'\n",
    "mapped_dba_to_brand['Littlejohn Portables'] = 'Premier Portables/ Prestigious Restrooms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00c3f66e-9739-40bf-997e-2be83515a2fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas['DBA'] = accident_df_pandas['DBA'].apply(\n",
    "    lambda dba: mapped_dba_to_brand[dba] if dba in mapped_dba_to_brand and dba not in fusionsite_regional_df_pandas[\"Brand\"].values else dba\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f3734d1-3d72-456c-a534-2e4d04d8abc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A Clean Portoco',\n",
       " 'A Sani-Can',\n",
       " 'Arkansas Portable Toilets',\n",
       " 'East Tennessee Portables',\n",
       " 'Forza Site Services',\n",
       " 'Portable Services',\n",
       " 'Stamback Services']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_location_dbas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0809e99-3778-43fb-a9ca-9ad27d13350b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Prepare a mapping dataframe from fusionsite data\n",
    "# Using Brand as the equivalent of DBA\n",
    "location_mapping = fusionsite_regional_df_pandas[~fusionsite_regional_df_pandas[\"Brand\"].isin(multiple_location_dbas)][['Brand', 'State', 'City', 'Zip', 'County']].copy()\n",
    "\n",
    "# Handle potential duplicates by keeping first occurrence for each Brand\n",
    "# This assumes that each Brand has consistent location info\n",
    "location_mapping = location_mapping.drop_duplicates(subset=['Brand'])\n",
    "\n",
    "# Rename columns for the merge\n",
    "location_mapping = location_mapping.rename(columns={\n",
    "    'Brand': 'DBA',\n",
    "    'State': 'dba_state',\n",
    "    'City': 'dba_city',\n",
    "    'Zip': 'dba_zip',\n",
    "    'County': 'dba_county'\n",
    "})\n",
    "\n",
    "# Merge the location data with the accident dataframe\n",
    "accident_df_pandas = pd.merge(\n",
    "    accident_df_pandas,\n",
    "    location_mapping,\n",
    "    on='DBA',\n",
    "    how='left'  # Keep all rows from accident_df even if no match found\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3529d739-8e15-4d78-b4b7-c788e06a22d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Using Driver Name to get DBA site location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8612d899-8c95-472f-a7ee-70afc5116fd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas[\"driver_id\"] = accident_df_pandas[\"driver_id\"].apply(\n",
    "    lambda x: str(int(x)) if pd.notna(x) else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fedd45a9-25d4-4fc2-b027-df12ecc6cbd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "non_matched_names = accident_df_pandas[(accident_df_pandas[\"DBA\"].isin(multiple_location_dbas)) &\n",
    "                   (accident_df_pandas[\"zip\"].isnull()) &\n",
    "                   (accident_df_pandas[\"city\"].isnull()) &\n",
    "                   (~accident_df_pandas[\"driver_id\"].isin(full_driver_details[\"Driver ID\"]))][\"insured_driver_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3add46d3-81f1-4957-927f-ffb5ab27a6ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "driver_detail_names = full_driver_details[full_driver_details[\"Driver\"].notnull()][\"Driver\"].unique()\n",
    "\n",
    "# Get unique DBA values that are not in the 'Brand' column\n",
    "unmatched_driver_names = accident_df_pandas[(~accident_df_pandas[\"insured_driver_name\"].isin(driver_detail_names))& \n",
    "                                            (accident_df_pandas[\"insured_driver_name\"].notnull())][\"insured_driver_name\"].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0823d9f4-bdf7-4eaf-9f93-a3aac0077cd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Map DBA values to the closest Brand using fuzzy matching\n",
    "mapped_names = {}\n",
    "for name in unmatched_driver_names:\n",
    "    closest_match, score = process.extractOne(str(name), driver_detail_names)\n",
    "    mapped_names[name] = closest_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6bb3a4b-fc32-45a2-a3a3-11bc62b1c60c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deleting some mappings after manual check\n",
    "del mapped_names['Bostick Delvin Miguel Question']\n",
    "del mapped_names['Micheal Roberts, Stephen Storti']\n",
    "del mapped_names['Larry Woodley']\n",
    "del mapped_names['unknown ']\n",
    "del mapped_names['unknown']\n",
    "del mapped_names['Javories Abraham']\n",
    "del mapped_names['Henry Tony']\n",
    "del mapped_names['none']\n",
    "del mapped_names['Raul Sauceda']\n",
    "del mapped_names['Edward Hart']\n",
    "del mapped_names['na']\n",
    "del mapped_names['Multiple drivers were at this site. ']\n",
    "del mapped_names[\"It happened back in May, they didn't tell us a price till August. No idea what day, time, or driver did this.\"]\n",
    "del mapped_names['Various Technicians']\n",
    "del mapped_names['Jonathan Thompson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb86831d-e87f-4c1a-878f-e25763e7d27c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "accident_df_pandas['insured_driver_name'] = accident_df_pandas['insured_driver_name'].apply(lambda name: mapped_names.get(name, None) if name in unmatched_driver_names else name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b7cda1f-a137-4a23-a352-7f85b0f3aecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "fs_cities = fusionsite_regional_df_pandas[\"City\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09418dcb-c446-459d-a4b2-c3cdc21746ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28 rows that need city updates\nUpdated city information for 11 out of 28 rows\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to avoid modifying the original\n",
    "updated_df = accident_df_pandas.copy()\n",
    "\n",
    "# Identify rows that need city updates based on the three conditions\n",
    "mask = (\n",
    "    (updated_df[\"DBA\"].isin(multiple_location_dbas)) &\n",
    "    (updated_df[\"zip\"].isnull()) &\n",
    "    (updated_df[\"city\"].isnull())\n",
    ")\n",
    "\n",
    "# Get the indices of rows that need updating\n",
    "rows_to_update = updated_df[mask].index\n",
    "print(f\"Found {len(rows_to_update)} rows that need city updates\")\n",
    "\n",
    "# Create a mapping from driver names to cities based on Groups column\n",
    "driver_city_map = {}\n",
    "\n",
    "for _, row in full_driver_details[[\"Driver\", \"Groups\"]].iterrows():\n",
    "    driver = row[\"Driver\"]\n",
    "    groups = str(row[\"Groups\"])  # Convert to string in case it's not\n",
    "    \n",
    "    # Skip if Groups is empty or null\n",
    "    if pd.isna(groups) or groups == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Look for city in groups using the pattern \"XX - CityName\"\n",
    "    city_match = re.search(r'\\w+ - (.+)', groups)\n",
    "    if city_match:\n",
    "        city = city_match.group(1).strip().lower()\n",
    "        \n",
    "        # Handle special case \"Fay\" -> \"Fayetteville\"\n",
    "        if \"fay\" in city:\n",
    "            city = \"Fayetteville\"\n",
    "        \n",
    "            \n",
    "        # Check if this city is in the known cities list\n",
    "        if any(fs_city.lower() == city.lower() for fs_city in fs_cities):\n",
    "            driver_city_map[driver] = city\n",
    "        \n",
    "        # If city not in fs_cities, check if it contains any fs_cities\n",
    "        else:\n",
    "            for fs_city in fs_cities:\n",
    "                if fs_city.lower() in city.lower():\n",
    "                    driver_city_map[driver] = fs_city\n",
    "                    break\n",
    "# Update the city information\n",
    "cities_found = 0\n",
    "\n",
    "for idx in rows_to_update:\n",
    "    driver_name = updated_df.loc[idx, \"insured_driver_name\"]\n",
    "    \n",
    "    # Check if we have a city for this driver\n",
    "    if driver_name in driver_city_map:\n",
    "        updated_df.loc[idx, \"dba_city\"] = driver_city_map[driver_name]\n",
    "        cities_found += 1\n",
    "\n",
    "print(f\"Updated city information for {cities_found} out of {len(rows_to_update)} rows\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2549be6c-2b9f-4ce1-9a0a-07c354e7d5f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "updated_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53ea47f4-5bae-49fb-8eee-9c1bdd86bd17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Mapping DBA location using General Manager Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95e4270b-af5e-4a6f-99da-88365fb401a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DBA                        General Manager               \n",
       "A Sani-Can                 Howard Salters                    31\n",
       "Portable Services          Andrew Munekata                   15\n",
       "East Tennessee Portables   Charlie Seivers                    8\n",
       "Arkansas Portable Toilets  Chris Greganti                     7\n",
       "                           Brix Byers                         6\n",
       "Forza Site Services        Albert Bernal                      4\n",
       "A Clean Portoco            michael perez                      3\n",
       "                           Michael Perez                      3\n",
       "Arkansas Portable Toilets  Bubba Wood                         2\n",
       "                           Bubba Wood                         2\n",
       "                           Devin Dauel                        2\n",
       "A Clean Portoco            MICHAEL PEREZ                      1\n",
       "Forza Site Services        Albert Bernal                      1\n",
       "Stamback Services          Joseph Schmuker                    1\n",
       "Arkansas Portable Toilets  Devin Dauel                        1\n",
       "East Tennessee Portables   CHARLIE SEIVERS                    1\n",
       "Arkansas Portable Toilets  Bubba Wood / Brittany Bohlman      1\n",
       "Stamback Services          Joseph Schmuker                    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df[updated_df[\"dba_city\"].isnull() &\n",
    "            updated_df[\"dba_zip\"].isnull() &\n",
    "             updated_df[\"dba_county\"].isnull()][[\"DBA\", \"General Manager \"]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79aa5854-2fa4-4539-9d09-b7b69b0777a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the mapping from manager names to locations (found these through online research)\n",
    "manager_location_map = {\n",
    "    \"michael perez\": \"Harlingen, Texas\",\n",
    "    \"Howard Salters\": \"Denver, NC\",\n",
    "    \"Andrew Munekata\": \"Augusta, GA\",\n",
    "    \"Charlie Seivers\": \"Knoxville, TN\",\n",
    "    \"Chris Greganti\": \"Little Rock, AK\",\n",
    "    \"Brix Byers\": \"Little Rock\",\n",
    "    \"Albert Bernal\": \"Lubbock, TX\",\n",
    "    \"Joseph Schmuker\": \"Wilcox, AZ\",\n",
    "    \"Bubba Wood\": \"Little Rock, AK\", \n",
    "    \"Devin Dauel\": \"Little Rock, AK\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5418a61c-845a-4792-a63e-6b283e59a161",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 90 city values and 93 state values based on General Manager names\n"
     ]
    }
   ],
   "source": [
    "#update_location_by_manager \n",
    "updated_df['gm_lower'] = updated_df['General Manager '].astype(str).str.lower().str.strip()\n",
    "\n",
    "\n",
    "# Track how many updates we make\n",
    "city_updates = 0\n",
    "state_updates = 0\n",
    "\n",
    "# Process each row\n",
    "for idx, row in updated_df.iterrows():\n",
    "    gm_name = row['gm_lower']\n",
    "    \n",
    "    # Check if the GM name is in our mapping\n",
    "    for manager, location in manager_location_map.items():\n",
    "        if manager.lower() in gm_name:\n",
    "            # Parse city and state from location\n",
    "            if ',' in location:\n",
    "                city, state = [part.strip() for part in location.split(',', 1)]\n",
    "            \n",
    "            # Update city if it's missing\n",
    "            if pd.isna(row['dba_city']):\n",
    "                updated_df.loc[idx, 'dba_city'] = city\n",
    "                city_updates += 1\n",
    "            \n",
    "            # Update state if it's missing and we have state info\n",
    "            if state and pd.isna(row['dba_state']):\n",
    "                updated_df.loc[idx, 'dba_state'] = state\n",
    "                state_updates += 1\n",
    "            \n",
    "            break  # Stop checking once we find a match\n",
    "\n",
    "# Drop the temporary column\n",
    "#updated_df = updated_df.drop(columns=['gm_lower'])\n",
    "print(f\"Updated {city_updates} city values and {state_updates} state values based on General Manager names\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e8043061-1e38-4e39-8081-7476f2ce0627",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Filling in missing location information based on existing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9291b91a-f7a3-4c94-8186-3e2bcb6e3a38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Fill in missing values for dba_state, dba_city, dba_county based on dba_zip\n",
    "updated_df['dba_state'] = updated_df.groupby('dba_zip')['dba_state'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "updated_df['dba_county'] = updated_df.groupby('dba_zip')['dba_county'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "\n",
    "# Step 2: Fill in missing values for dba_state and dba_city based on dba_city\n",
    "updated_df['dba_state'] = updated_df.groupby('dba_city')['dba_state'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "updated_df['dba_zip'] = updated_df.groupby('dba_city')['dba_zip'].transform(lambda x: x.fillna(method='ffill').fillna(method='bfill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5867ed6-bad0-469b-af1e-9319fb81a5e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the columns you want to use in us_city_states_pandas are non-null\n",
    "fusionsite_regional_df_pandas_clean = fusionsite_regional_df_pandas.dropna(subset=['State.1', 'City', 'County', 'Zip'])\n",
    "\n",
    "# lower case all columns \n",
    "fusionsite_regional_df_pandas_clean = fusionsite_regional_df_pandas.dropna(subset=['State.1', 'City', 'County', 'Zip']).applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "# lower case dba_state, dba_city, dba_county in updated_df\n",
    "# Lower case dba_state, dba_city, dba_county in updated_df\n",
    "updated_df['dba_state'] = updated_df['dba_state'].str.lower()\n",
    "updated_df['dba_city'] = updated_df['dba_city'].str.lower()\n",
    "updated_df['dba_county'] = updated_df['dba_county'].str.lower()\n",
    "\n",
    "# Iterate over the rows of updated_df to fill in the missing values\n",
    "for idx, row in updated_df.iterrows():\n",
    "    # Check if the value for dba_state, dba_city, or dba_county is null\n",
    "    if pd.isnull(row['dba_state']) or pd.isnull(row['dba_city']) or pd.isnull(row['dba_county']):\n",
    "        \n",
    "        # Find matching row(s) in us_city_states_pandas_clean based on city, county, or zip\n",
    "        matches = fusionsite_regional_df_pandas_clean[\n",
    "            (fusionsite_regional_df_pandas_clean['County'] == row['dba_county']) |\n",
    "            (fusionsite_regional_df_pandas_clean['City'] == row['dba_city']) |\n",
    "            (fusionsite_regional_df_pandas_clean['Zip'] == row['dba_zip'])\n",
    "        ]\n",
    "        \n",
    "        # If we find any match, use the first match to fill the missing values\n",
    "        if not matches.empty:\n",
    "            # Fill missing values with matched data\n",
    "            updated_df.at[idx, 'dba_state'] = matches.iloc[0]['State.1'] \n",
    "            updated_df.at[idx, 'dba_city'] = matches.iloc[0]['City']\n",
    "            updated_df.at[idx, 'dba_county'] = matches.iloc[0]['County']\n",
    "            updated_df.at[idx, 'dba_zip'] = matches.iloc[0]['Zip']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad4a602e-025a-4503-a2ff-1c28dd894e0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lowercase all columns \n",
    "updated_df = updated_df.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34ac7e1f-ec79-4324-a4a3-a09af930b986",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over the rows of updated_df to fill in the missing values\n",
    "for idx, row in updated_df.iterrows():\n",
    "    # Check if the value for dba_state, dba_city, or dba_county is null\n",
    "    if pd.isnull(row['state']) or pd.isnull(row['city']):\n",
    "        \n",
    "        # Find matching row(s) in us_city_states_pandas_clean based on city, county, or zip\n",
    "        matches = fusionsite_regional_df_pandas_clean[\n",
    "            ((fusionsite_regional_df_pandas_clean['City'] == row['city']) & \n",
    "             (fusionsite_regional_df_pandas_clean['State.1'] == row['state'])) |\n",
    "            (fusionsite_regional_df_pandas_clean['Zip'] == row['dba_zip'])\n",
    "        ]\n",
    "        \n",
    "        # If we find any match, use the first match to fill the missing values\n",
    "        if not matches.empty:\n",
    "            # Fill missing values with matched data\n",
    "            updated_df.at[idx, 'state'] = matches.iloc[0]['State.1'] \n",
    "            updated_df.at[idx, 'city'] = matches.iloc[0]['City']\n",
    "            updated_df.at[idx, 'zip'] = matches.iloc[0]['Zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f4b6a3b-ddf0-4d46-b06f-e52a7b4f5dcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# lower case all columns \n",
    "us_city_states_pandas = us_city_states_pandas.applymap(lambda x: x.lower() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a7af234-0e2b-4517-9351-c1b355a7aed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Iterate over the rows of updated_df to fill in the missing values\n",
    "for idx, row in updated_df.iterrows():\n",
    "    # Check if the value for dba_state, dba_city, or dba_county is null\n",
    "    if pd.isnull(row['state']) or pd.isnull(row['city']) or pd.isnull(\"\"):\n",
    "        \n",
    "        # Find matching row(s) in us_city_states_pandas_clean based on city, county, or zip\n",
    "        matches = us_city_states_pandas[\n",
    "            ((us_city_states_pandas['city'] == row['city']) & \n",
    "             (us_city_states_pandas['state_id'] == row['state'])) \n",
    "        ]\n",
    "        \n",
    "        # If we find any match, use the first match to fill the missing values\n",
    "        if not matches.empty:\n",
    "            # Fill missing values with matched data\n",
    "            updated_df.at[idx, 'state'] = matches.iloc[0]['state_id'] \n",
    "            updated_df.at[idx, 'city'] = matches.iloc[0]['city']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6afd63e5-1f9b-4ecf-bd06-c6348451729b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for idx, row in updated_df.iterrows():\n",
    "    if pd.isna(row['zip']):\n",
    "        match = us_city_states_pandas[\n",
    "            (us_city_states_pandas['state_id'] == row['state']) & \n",
    "            (us_city_states_pandas['city'] == row['city'])\n",
    "        ]\n",
    "        if not match.empty:\n",
    "            updated_df.at[idx, 'zip'] = match.iloc[0]['zips']\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b03cd92-07c0-4da9-b59b-d3c18dd2a341",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df[(updated_df['zip'].isnull()) & (updated_df['dba_zip'].isnull())].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e68d4e3-cc1b-4ad0-b2f5-d2ceb30a493f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There are 17 accidents we cannot map to a location using the address of the accident or the address of the DBA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22bf2cf5-c78d-449f-9d61-68885f9e2197",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['1471', '1144', 'Old South Auto Mechanic', ..., '0897', '2359',\n",
       "       '894'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_driver_details[full_driver_details[\"Driver ID\"].notnull()][\"Driver ID\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c24506-4cf9-49ae-94af-55603ec7d8de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(17, 30)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_df[((updated_df['zip'].isnull()) & \n",
    "            (updated_df['dba_zip'].isnull()) &\n",
    "            (~updated_df[\"driver_id\"].isin(full_driver_details[full_driver_details[\"Driver ID\"].notnull()][\"Driver ID\"].unique())))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69c0e39e-bf1f-4795-98a4-0a8ee37053a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "updated_df = updated_df[~((updated_df['zip'].isnull()) & \n",
    "            (updated_df['dba_zip'].isnull()) &\n",
    "            (~updated_df[\"driver_id\"].isin(full_driver_details[full_driver_details[\"Driver ID\"].notnull()][\"Driver ID\"].unique())))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcbf9c16-7596-4565-93a2-092f71f6288c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.ipykernel/13151/command-1626257048687653-514209455:58: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['zip'] = df['zip'].apply(clean_zip)\n/root/.ipykernel/13151/command-1626257048687653-514209455:59: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['dba_zip'] = df['dba_zip'].apply(clean_zip)\n"
     ]
    }
   ],
   "source": [
    "# Define the schema for the DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"Location of Accident (street, city, state)\", StringType(), True),\n",
    "    StructField(\"DBA\", StringType(), True),\n",
    "    StructField(\"General Manager\", StringType(), True),\n",
    "    StructField(\"Date of Accident\", StringType(), True),\n",
    "    StructField(\"Date Reported\", StringType(), True),\n",
    "    StructField(\"Fatality\", StringType(), True),\n",
    "    StructField(\"insured_driver_name\", StringType(), True),\n",
    "    StructField(\"Copy of Sate or Insurance Report\", StringType(), True),\n",
    "    StructField(\"Severity\", StringType(), True),\n",
    "    StructField(\"Summary of Accident\", StringType(), True),\n",
    "    StructField(\"Claim Number\", StringType(), True),\n",
    "    StructField(\"Total Incurred\", FloatType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Region\", StringType(), True),\n",
    "    StructField(\"Time of Accident\", StringType(), True),\n",
    "    StructField(\"APMM Recordable\", StringType(), True),\n",
    "    StructField(\"Notes\", StringType(), True),\n",
    "    StructField(\"insured_first_name\", StringType(), True),\n",
    "    StructField(\"insured_last_name\", StringType(), True),\n",
    "    StructField(\"driver_first_name\", StringType(), True),\n",
    "    StructField(\"driver_last_name\", StringType(), True),\n",
    "    StructField(\"driver_id\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"zip\", StringType(), True),  # Changed from float to string to preserve leading zeros\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"dba_state\", StringType(), True),\n",
    "    StructField(\"dba_city\", StringType(), True),\n",
    "    StructField(\"dba_zip\", StringType(), True),  # Changed from float to string\n",
    "    StructField(\"dba_county\", StringType(), True),\n",
    "    StructField(\"gm_lower\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "def cleanup_zip_codes(df):\n",
    "    # Handle 'zip' column\n",
    "    def clean_zip(x):\n",
    "        if pd.isna(x):\n",
    "            return None\n",
    "        \n",
    "        # Convert to string first to handle both floats and strings\n",
    "        x_str = str(x)\n",
    "        \n",
    "        # Check if it contains spaces (multiple zip codes)\n",
    "        if ' ' in x_str:\n",
    "            return x_str  # Keep multiple zip codes as is\n",
    "        \n",
    "        # For single zip codes, remove decimal part if it's a float\n",
    "        try:\n",
    "            # Try to convert to int to remove decimal, but only if it's a number without spaces\n",
    "            return str(int(float(x_str)))\n",
    "        except ValueError:\n",
    "            # If conversion fails, return as is\n",
    "            return x_str\n",
    "    \n",
    "    # Apply the function to both zip columns\n",
    "    df['zip'] = df['zip'].apply(clean_zip)\n",
    "    df['dba_zip'] = df['dba_zip'].apply(clean_zip)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply the cleanup function\n",
    "updated_df = cleanup_zip_codes(updated_df)\n",
    "\n",
    "# Create Spark DataFrame with the defined schema\n",
    "updated_df_spark = spark.createDataFrame(updated_df, schema=schema)\n",
    "\n",
    "# Write to parquet\n",
    "updated_df_spark.write.mode(\"overwrite\").parquet(\"/FileStore/intermediate_output/accidents_wth_location\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "accident_data_location_processing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}